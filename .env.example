# ============================================
# AI AGENT MASTERY - TYPESCRIPT EDITION
# Environment Configuration
# ============================================

# --------------------------------------------
# LLM Provider Configuration
# --------------------------------------------

# The provider for your LLM
# Options: openai, anthropic, groq, mistral, cohere, ollama
LLM_PROVIDER=openai

# Base URL for the LLM API
# OpenAI: https://api.openai.com/v1
# Anthropic: https://api.anthropic.com
# Groq: https://api.groq.com/openai/v1
# Ollama (local): http://localhost:11434/v1
LLM_BASE_URL=https://api.openai.com/v1

# API Key for your LLM provider
# OpenAI: https://platform.openai.com/api-keys
# Anthropic: https://console.anthropic.com/settings/keys
# Groq: https://console.groq.com/keys
# Ollama: Set to "ollama" (placeholder)
LLM_API_KEY=your_api_key_here

# The LLM model for agent reasoning (must support function/tool calling)
# OpenAI: gpt-4o, gpt-4o-mini, gpt-4-turbo
# Anthropic: claude-3-5-sonnet-20250219, claude-3-7-sonnet-20250219
# Groq: llama-3.3-70b-versatile, mixtral-8x7b-32768
# Ollama: qwen2.5:14b-instruct-8k, mistral:7b-instruct
LLM_MODEL=gpt-4o-mini

# The LLM model for image/vision analysis (must support vision)
# OpenAI: gpt-4o, gpt-4o-mini
# Anthropic: claude-3-5-sonnet-20250219, claude-3-7-sonnet-20250219
# Ollama: llava:7b, llava:13b
VISION_LLM_MODEL=gpt-4o-mini

# --------------------------------------------
# Embedding Model Configuration
# --------------------------------------------

# The provider for your embedding model
# Options: openai, ollama
# Note: Anthropic, Groq, and others don't provide embedding models
EMBEDDING_PROVIDER=openai

# Base URL for embedding API
# OpenAI: https://api.openai.com/v1
# Ollama: http://localhost:11434/v1
EMBEDDING_BASE_URL=https://api.openai.com/v1

# API Key for embedding provider
EMBEDDING_API_KEY=your_embedding_api_key_here

# The embedding model for RAG and vector search
# IMPORTANT: Dimensions must match your database vector column!
# OpenAI: text-embedding-3-small (1536 dims), text-embedding-3-large (3072 dims)
# Ollama: nomic-embed-text (768 dims), mxbai-embed-large (1024 dims)
EMBEDDING_MODEL=text-embedding-3-small

# Embedding dimensions (must match EMBEDDING_MODEL)
# text-embedding-3-small: 1536
# nomic-embed-text: 768
EMBEDDING_DIMENSIONS=1536

# --------------------------------------------
# Database Configuration (PostgreSQL + pgvector)
# --------------------------------------------

# PostgreSQL connection URL with pgvector extension
# Format: postgresql://[user]:[password]@[host]:[port]/[database]
# Supabase: Get from Project Settings -> Database -> Connection String (Transaction Pooler)
# Local: postgresql://postgres:password@localhost:5432/ai_agent_mastery
DATABASE_URL=postgresql://postgres:password@localhost:5432/ai_agent_mastery

# Direct database connection (for migrations, not pooled)
# Supabase: Project Settings -> Database -> Connection String (Direct)
DIRECT_DATABASE_URL=

# --------------------------------------------
# Supabase Configuration
# --------------------------------------------

# Supabase project URL
# Format: https://[project-id].supabase.co
# Local Supabase: http://localhost:8000
SUPABASE_URL=https://your-project.supabase.co

# Supabase anonymous key (for frontend client-side)
# Get from Project Settings -> API -> Project API keys -> anon/public
SUPABASE_ANON_KEY=your_anon_key_here

# Supabase service role key (for backend server-side, has elevated privileges)
# Get from Project Settings -> API -> Project API keys -> service_role
# WARNING: Keep this secret! Never expose in frontend code
SUPABASE_SERVICE_KEY=your_service_key_here

# --------------------------------------------
# Web Search Configuration
# --------------------------------------------

# Choose ONE: Brave API or SearXNG (leave the other empty)

# Brave Search API Key (recommended for production)
# Get from: https://api.search.brave.com/app/keys
BRAVE_API_KEY=

# SearXNG endpoint (for self-hosted search)
# Local AI package: http://localhost:8081 (outside Docker) or http://searxng:8080 (inside Docker)
SEARXNG_BASE_URL=

# --------------------------------------------
# External Integrations (Optional - for Module 7)
# --------------------------------------------

# Google OAuth credentials (for Gmail and Google Drive)
# Get from: https://console.cloud.google.com/apis/credentials
GOOGLE_CLIENT_ID=
GOOGLE_CLIENT_SECRET=
GOOGLE_REDIRECT_URI=http://localhost:3000/api/auth/google/callback

# Asana API (for task management - Module 7.7)
# Get from: https://app.asana.com/0/my-apps
ASANA_ACCESS_TOKEN=

# --------------------------------------------
# Observability & Monitoring
# --------------------------------------------

# Langfuse (LLM observability)
# Get from: https://cloud.langfuse.com
LANGFUSE_PUBLIC_KEY=
LANGFUSE_SECRET_KEY=
LANGFUSE_HOST=https://cloud.langfuse.com

# --------------------------------------------
# Application Configuration
# --------------------------------------------

# Node environment
NODE_ENV=development

# Backend API server
API_PORT=3001
API_HOST=0.0.0.0

# Frontend development server
FRONTEND_PORT=5173

# CORS allowed origins (comma-separated)
CORS_ORIGINS=http://localhost:5173,http://localhost:3000

# Session secret for authentication
SESSION_SECRET=your_random_session_secret_here_change_in_production

# --------------------------------------------
# RAG Pipeline Configuration
# --------------------------------------------

# Directory to watch for new documents (local file RAG)
RAG_WATCH_DIRECTORY=./documents

# Google Drive folder ID to monitor (if using Google Drive RAG)
GOOGLE_DRIVE_FOLDER_ID=

# Chunk size for document splitting (in characters)
CHUNK_SIZE=1000

# Chunk overlap for document splitting (in characters)
CHUNK_OVERLAP=200

# Top K results to retrieve from vector search
RAG_TOP_K=5

# Similarity threshold (0-1, cosine similarity)
RAG_SIMILARITY_THRESHOLD=0.7

# --------------------------------------------
# Long-Term Memory Configuration (Mem0-like)
# --------------------------------------------

# Enable long-term memory
ENABLE_MEMORY=true

# Memory retention period (in days, 0 = unlimited)
MEMORY_RETENTION_DAYS=90

# --------------------------------------------
# Code Execution Sandbox (Optional - for code tool)
# --------------------------------------------

# Enable code execution tool (security risk if not properly sandboxed)
ENABLE_CODE_EXECUTION=false

# Execution timeout (milliseconds)
CODE_EXECUTION_TIMEOUT=5000

# --------------------------------------------
# Rate Limiting
# --------------------------------------------

# Requests per minute per user
RATE_LIMIT_RPM=60

# Maximum concurrent requests
MAX_CONCURRENT_REQUESTS=10

# --------------------------------------------
# Development Tools
# --------------------------------------------

# Enable debug logging
DEBUG=false

# Log level (error, warn, info, debug)
LOG_LEVEL=info

# Enable OpenTelemetry tracing
ENABLE_TRACING=false
